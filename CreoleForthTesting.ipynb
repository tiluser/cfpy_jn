{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b76dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name : Joseph M. O'Connor\n",
    "# Date : April 2023\n",
    "# Project : Creole Forth for Python in a Jupyter notebook demo.\n",
    "#           Has the following sections:\n",
    "#           1. Initial setup with simple examples.\n",
    "#           2. Machine learning example that builds and validatesa binary classification system to mark sites as phishing or\n",
    "#              non-phishing. \n",
    "#           3. To-do list/daily log app using the Dropbox API. \n",
    "# References: \n",
    "# https://www.statology.org/plot-roc-curve-python/\n",
    "# https://python.plainenglish.io/using-k-fold-cross-validation-to-evaluate-the-performance-of-logistic-regression-4439215f24c4\n",
    "# Notebook and associated code is at http://github.com/tiluser/cfpy_jn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b02e06",
   "metadata": {},
   "source": [
    "Overview of demo execution\n",
    "-----------------------------------------\n",
    "\n",
    "1. Import the Creole Forth scripting language and set up some preliminary defs\n",
    "2. Do some demo executions using the Python functions with embedded Forth commands\n",
    "3. It's inconvenient to embed Forth in Python every time you want to do domething - what's the alternative?\n",
    "4. Creating you own kernel - a nontrivial undertaking, even with Xeus to make it simple.\n",
    "5. Path of least resistance - use magic commands. \n",
    "6. Demo executions with magic commands - line and cell. %cfpy and %compdef for line execution and compilation, \n",
    "   %%cfpy and %%compdef for cell execution and compilation. \n",
    "7. Example(s) from my machine learning class.\n",
    "8. Demo app - todo list/daily log. Front end is in Lazarus. It builds and saves a todo list, then transfers it \n",
    "   to Dropbox. It also builds and saves a daily log entry.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b59467",
   "metadata": {},
   "source": [
    "Why do Forth in a Jupyter notebook?\n",
    "-----------------------------------------------------\n",
    "\n",
    "- Jupyter notebook is very commonly used in machine learning/data science.\n",
    "- Very interactive and easy to use, like a one-dimensional spreadsheet. \n",
    "- Supported in many different programming languages. Commonly Python, R, and Julia are used.\n",
    "- Has lots of built-in tools.\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0e546",
   "metadata": {},
   "source": [
    "Is Forth supported?\n",
    "----------------------------\n",
    "\n",
    "- Not directly, but Python is.\n",
    "- That means a Python written in Forth can work.\n",
    "- Fortunately, I’ve written a version for Python.\n",
    "- We’ll be taking a look at how it can be used with Jupyter notebook today. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a43f36",
   "metadata": {},
   "source": [
    "Initial setup\n",
    "-----------------\n",
    "\n",
    "- Import Creole Forth for Python along with two helper definitions to execute and compile the Forth Code.\n",
    "- Then show some simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93daa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple wrapper definitions to execute and compile Forth code\n",
    "from CreoleForth import *\n",
    "\n",
    "def execCF(oneLine):\n",
    "    gsp.InputArea = oneLine\n",
    "    cfb1.Modules.Interpreter.doParseInput(gsp)\n",
    "    cfb1.Modules.Interpreter.doOuter(gsp)\n",
    "    return None\n",
    "\n",
    "def buildColon(oneLine):\n",
    "    gsp.InputArea = oneLine\n",
    "    cfb1.buildHighLevel(gsp,oneLine,\"\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "execCF('HELLO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64022368",
   "metadata": {},
   "outputs": [],
   "source": [
    "execCF('TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "execCF('3 4 + .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "execCF('VLIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dca9fe",
   "metadata": {},
   "source": [
    "Limitations to this approach\n",
    "----------------------------------------\n",
    "\n",
    "- Wrapping Forth code inside a Python function is cumbersome.\n",
    "- It would be nice to do it more conveniently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ef919",
   "metadata": {},
   "source": [
    "One alternative\n",
    "----------------------\n",
    "\n",
    "- Create your own Jupyter notebook kernel.\n",
    "- There are tools available such as Xeus which are designed for this.\n",
    "- It's still a fair amount of work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb98a8",
   "metadata": {},
   "source": [
    "A simpler solution\n",
    "--------------------------\n",
    "\n",
    "- Stick with the Python kernel.\n",
    "- Python has a facility called magic commands, which allow the user to wrap a line or a cell inside a function and then call the   function.\n",
    "- It only requires writing a few lines of code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70e651e5",
   "metadata": {},
   "source": [
    "The magic commands\n",
    "-------------------------------\n",
    "\n",
    "- %cfpy – executes Forth commands on a single line.\n",
    "- %%cfpy – executes Forth commands in a cell.\n",
    "- %compdef – compiles Forth on a single line.\n",
    "- %%compdef – compiles Forth in a cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed98a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up magic commands\n",
    "from IPython.core.magic import (register_line_magic, register_cell_magic, register_line_cell_magic)\n",
    "\n",
    "@register_line_magic\n",
    "def cfpy(line):\n",
    "    \"my line magic\"\n",
    "    return execCF(line)\n",
    "\n",
    "@register_line_magic\n",
    "def compdef(line):\n",
    "    return buildColon(line)\n",
    "\n",
    "@register_cell_magic\n",
    "def cfpy(line,cell):\n",
    "    \"my cell magic\"\n",
    "    line=\"\"\n",
    "    return line, execCF(cell)\n",
    "\n",
    "@register_cell_magic\n",
    "def compdef(line, cell):\n",
    "    return line, buildColon(cell)\n",
    "   \n",
    "@register_line_cell_magic\n",
    "def lcmagic(line, cell=None):\n",
    "    \"Magic that works both as %lcmagic and as %%lcmagic\"\n",
    "    if cell is None:\n",
    "        print(\"Called as line magic\")\n",
    "        return line\n",
    "    else:\n",
    "        print(\"Called as cell magic\")\n",
    "        return line, cell\n",
    "\n",
    "# In an interactive session, we need to delete these to avoid\n",
    "# name conflicts for automagic to work on line magics.\n",
    "del lcmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170ffd34",
   "metadata": {},
   "source": [
    "Use of magic commands - some simple examples\n",
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b27303",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy HELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49417454",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy\n",
    "\n",
    "HELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%compdef : T2 TEST TEST ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087417ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d101971",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%compdef\n",
    ": TESTS 0 DO TEST LOOP ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy 3 TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy 3 4 + ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346238b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy\n",
    "// HELLO if 1, TULIP if 0\n",
    "0 HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of building primitives directly within the notebook. The primitives can be based on instance methods,\n",
    "# static methods, or standalone functions. Primitives should always take the GlobalSimpleProps object gsp as an argument. \n",
    "import os\n",
    "\n",
    "class Stuff:\n",
    "    def __init__(self):\n",
    "        self.Title = \"Just some test stuff\"\n",
    "\n",
    "    # ( -- ) prints \"This is cool\"\n",
    "    def doCool(self, gsp):\n",
    "        print(\"This is cool\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def doMore(gsp):\n",
    "        print(\"This is more\")\n",
    "    \n",
    "    def doMore2(gsp):\n",
    "        print(\"This is more 2\")\n",
    "    doMore2 = staticmethod(doMore2)\n",
    "               \n",
    "stuff = Stuff()\n",
    "\n",
    "def foobar(gsp):\n",
    "    print(\"This is a foobar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ce9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After defining the code for the primitives, add them to the dictionary. Then they're immediately available for execution.\n",
    "cfb1.buildPrimitive(\"COOL\",stuff.doCool, \"stuff.doCool\", \"FORTH\", \"COMPINPF\",\"( -- ) Prints this is cool\")\n",
    "cfb1.buildPrimitive(\"FOOBAR\",foobar, \"foobar\", \"APPSPEC\", \"COMPINPF\",\"( -- ) Foobaring away\")\n",
    "cfb1.buildPrimitive(\"MORE2\",Stuff.doMore2, \"Stuff.doMore2\", \"APPSPEC\", \"COMPINPF\",\"( -- ) More2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy FOOBAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2842bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy COOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy MORE2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff89d2",
   "metadata": {},
   "source": [
    "Machine learning demo\n",
    "---------------------------------\n",
    "\n",
    "- Data analyzed is of thousands of urls which are classified as phishing, suspicious or legitimate.\n",
    "- Exploratory data analysis, data cleaning, and looking for data correlations was initially done.\n",
    "- It was followed up with binary classification to mark sites as phishing or non-phishing.\n",
    "- First logistic regression was done with plots to show the effectiveness of the model. \n",
    "- It was then validated with K-fold cross-validation. \n",
    "- This is a methodology that resamples data in order to find the efficacy of machine learning models. \n",
    "- Data is split into K subsamples. Each subsample is used as a testing set, while the remainder are used as training sets.\n",
    "- It checks the performance of the model on new data in order to avoid overfitting or underfitting the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in all the libraries needed. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3273bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the primitives needed for the exercise\n",
    "\n",
    "# ( -- ) Empties the data stack\n",
    "def doClearDataStack(gsp):\n",
    "    gsp.DataStack[:] = []\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"CLSDS\", doClearDataStack, \"doClearDataStack\", \"APPSPEC\", \"COMPINPF\",\"(  -- ) Empties the data stack\")\n",
    "\n",
    "# ( csvfile -- df ) Loads a csv data set\n",
    "def doLoadCsv(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    csvFile = gsp.Scratch\n",
    "    df = pd.read_csv(csvFile)\n",
    "    gsp.Scratch = df\n",
    "    gsp.push(gsp.DataStack) \n",
    "    return 0\n",
    "     \n",
    "cfb1.buildPrimitive(\"LOADCSV\", doLoadCsv, \"doLoadCsv\", \"APPSPEC\", \"COMPINPF\",\"( csvfile -- df ) Loads a csv data set\")\n",
    "\n",
    "# ( df -- ) Outputs the correlation matrix\n",
    "def doCorrMatrix(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    df = gsp.Scratch\n",
    "    corrmat = df.corr()\n",
    "    print(corrmat)\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"CORRMAT\", doCorrMatrix, \"doCorrMatrix\", \"APPSPEC\", \"COMPINPF\",\"( df -- ) Outputs the correlation matrix\")\n",
    "\n",
    "# Collapse values in dataframe from -1, 0, and 1 to 0 and 1.  -1 and 0 become 0 (suspicious or phishing, 1 stays 1\n",
    "#    (non-phishing).\n",
    "def collapse_vals(val):\n",
    "    lookup = {-1 : 0, 0 : 0, 1 : 1}\n",
    "    return lookup[val]\n",
    "\n",
    "# ( df -- dfc ) Collapse all highly correlated fields (r > .5) to 0 and 1                                                                                   \n",
    "def doCollapseFields(gsp):\n",
    "    dfc = pd.DataFrame()\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    df = gsp.Scratch                                                                                  \n",
    "    dfc['Prefix_Suffix'] = [collapse_vals(val) for val in df['Prefix_Suffix']]\n",
    "    dfc['having_Sub_Domain'] = [collapse_vals(val) for val in df['having_Sub_Domain']]\n",
    "    dfc['SSLfinal_State'] = [collapse_vals(val) for val in df['SSLfinal_State']]\n",
    "    dfc['Domain_registeration_length'] = [collapse_vals(val) for val in df['Domain_registeration_length']]\n",
    "    dfc['age_of_domain'] = [collapse_vals(val) for val in df['age_of_domain']]\n",
    "    dfc['web_traffic'] = [collapse_vals(val) for val in df['web_traffic']]\n",
    "    dfc['Page_Rank'] = [collapse_vals(val) for val in df['Page_Rank']]\n",
    "    dfc['Google_Index'] = [collapse_vals(val) for val in df['Google_Index']]\n",
    "    dfc['Result'] = [collapse_vals(val) for val in df['Result']]\n",
    "    gsp.Scratch = dfc\n",
    "    gsp.push(gsp.DataStack) \n",
    "    return 0\n",
    "                                                                                     \n",
    "cfb1.buildPrimitive(\"COLLAPSE_FIELDS\", doCollapseFields, \"doCollapseFields\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( df -- dfc ) Collapse all highly correlated fields (r > .5) to 0 and 1\")\n",
    "\n",
    "# ( dfc -- X  y ) Partition data into independent and dependent dataframes\n",
    "def doPartitionData(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    dfc = gsp.Scratch       \n",
    "    y = dfc['Result']\n",
    "    X = dfc.drop('Result', axis='columns')\n",
    "    gsp.Scratch = X\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = y\n",
    "    gsp.push(gsp.DataStack)\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"PARTITION_DATA\", doPartitionData, \"doPartitionData\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( dfc -- X  y ) Partition data into independent and dependent dataframes\")\n",
    "\n",
    "# ( X field --  ) Does a pie chart of one of the fields for the X dataframe \n",
    "def doPiechartX(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    field = gsp.Scratch\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    X = gsp.Scratch \n",
    "    a_X = X[field].value_counts().plot.pie(autopct='%.2f')\n",
    "    _ = a_X.set_title(field)\n",
    "    return 0\n",
    "    \n",
    "cfb1.buildPrimitive(\"PIECHARTX\", doPiechartX, \"doPieChartX\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( X field --  ) Does a pie chart of one of the fields for the X dataframe\")\n",
    "\n",
    "# ( y --  ) Does a pie chart of one of the fields for the y dataframe \n",
    "def doPiechartY(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    y = gsp.Scratch \n",
    "    ay = y.value_counts().plot.pie(autopct='%.2f')\n",
    "    _ = ay.set_title('Result')\n",
    "    return 0\n",
    "    \n",
    "cfb1.buildPrimitive(\"PIECHARTY\", doPiechartY, \"doPieChartY\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( y --  ) Does a pie chart for the result of the Y dataframe\")\n",
    "\n",
    "# ( X y -- X_numpy y_numpy ) Convert to numpy matrices \n",
    "def doToMatrix(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    y = gsp.Scratch \n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    X = gsp.Scratch \n",
    "    X_numpy = X.to_numpy()\n",
    "    y_numpy = y.to_numpy()\n",
    "    gsp.Scratch = X_numpy\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = y_numpy\n",
    "    gsp.push(gsp.DataStack)\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\">MATRIX\", doToMatrix, \"doToMatrix\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( X y  -- X_numpy Y_numpy  ) Convert to numpy matrixes\")\n",
    "\n",
    "# ( X_numpy y_numpy -- x_train x_test y_train y_test ) Does the train/test split\n",
    "def doTrainTestSplit(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    y_numpy = gsp.Scratch \n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    X_numpy = gsp.Scratch \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_numpy, y_numpy, test_size=0.25,shuffle=True)\n",
    "    gsp.Scratch = x_train\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = x_test\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = y_train\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = y_test\n",
    "    gsp.push(gsp.DataStack)\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"TRAIN_TEST_SPLIT\", doTrainTestSplit, \"doTrainTestSplit\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( X_numpy y_numpy -- x_train x_test y_train y_test ) Does the train/test split\")\n",
    "\n",
    "# ( X_numpy -- model ) Compile, fit, and summarize logistic regression model\n",
    "def doLogitCompile(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    X_numpy = gsp.Scratch     \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim = len(X_numpy[0,:]), activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "    gsp.Scratch = model\n",
    "    gsp.push(gsp.DataStack)\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"LOGITCOMP\", doLogitCompile, \"doLogitCompile\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( X_numpy -- model ) Compile, fit, and summarize logistic regression model\")\n",
    "\n",
    "# ( model x_train x_test y_train y_test epochs -- x_train x_test y_train y_test train ) trains the model\n",
    "def doTrainModel(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    epochsNum = int(gsp.Scratch)\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    y_test = gsp.Scratch \n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    y_train = gsp.Scratch \n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    x_test = gsp.Scratch \n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    x_train = gsp.Scratch  \n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    model = gsp.Scratch \n",
    "    train = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=epochsNum)\n",
    "    gsp.Scratch = x_train\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = x_test\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = y_train\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = y_test\n",
    "    gsp.push(gsp.DataStack)\n",
    "    gsp.Scratch = train\n",
    "    gsp.push(gsp.DataStack)\n",
    "    return 0\n",
    "    \n",
    "cfb1.buildPrimitive(\"TRAIN_MODEL\", doTrainModel, \"doTrainModel\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( model x_train x_test y_train y_test epochs -- x_train x_test y_train y_test train ) trains the mode\")\n",
    " \n",
    "# ( train -- ) plot of loss over epochs\n",
    "def doPlotLoss(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    train = gsp.Scratch \n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(train.history['loss'],label='Training loss')\n",
    "    plt.plot(train.history['val_loss'],label='Validation loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"PLOT_LOSS\", doPlotLoss, \"doPlotLoss\", \"APPSPEC\", \"COMPINPF\",\"( train -- ) plot of loss over epochs\")\n",
    "\n",
    "# ( train -- ) plot of accuracy over epochs\n",
    "def doPlotAccuracy(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    train = gsp.Scratch \n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(train.history['accuracy'],label='Training accuracy')\n",
    "    plt.plot(train.history['val_accuracy'],label='Validation accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"PLOT_ACC\", doPlotAccuracy, \"doPlotAccuracy\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( train -- ) plot of accuracy over epochs\")\n",
    "\n",
    "# ( x_train y_train -- ) Validate model with K-fold cross-validation\n",
    "def doCrossValidation(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    y_train = gsp.Scratch \n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    x_train = gsp.Scratch  \n",
    "    kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "    # Output the accuracy. Calculate the mean and std across all folds. \n",
    "    print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"CROSSVAL\", doCrossValidation, \"doCrossValidation\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( x_train y_train -- ) Validate model with K-fold cross-validation\")\n",
    "\n",
    "# ( x_train x_test y_train y_test -- ) fit the model using the training data and plot the ROC curve\n",
    "def doPlotRocCurve(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    y_test = gsp.Scratch \n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    y_train = gsp.Scratch\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    x_test = gsp.Scratch\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    x_train = gsp.Scratch  \n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(x_train,y_train)   \n",
    "    y_pred_proba = model.predict_proba(x_test)[::,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "    # create ROC curve\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"PLOTROC\", doPlotRocCurve, \"doPlotRocCurve\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( x_train x_test y_train y_test -- ) fit the model using the training data and plot the ROC curve\")\n",
    "                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e59f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%compdef\n",
    ": SETPART  \n",
    "    LOADCSV COLLAPSE_FIELDS PARTITION_DATA ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769dd6a",
   "metadata": {},
   "source": [
    "Print a correlation matrix\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f825c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy \n",
    "\n",
    "CLSDS kf_dataset.csv LOADCSV COLLAPSE_FIELDS CORRMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb247da4",
   "metadata": {},
   "source": [
    "Piechart of dependent variable\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy \n",
    "\n",
    "CLSDS kf_dataset.csv SETPART PIECHARTY DROP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4583ac4a",
   "metadata": {},
   "source": [
    "Piechart of one of the predictor variables\n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy \n",
    "\n",
    "CLSDS kf_dataset.csv SETPART SWAP Prefix_Suffix PIECHARTX DROP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc070b2",
   "metadata": {},
   "source": [
    "- Compile the logistic regression model\n",
    "- Do a train/test split\n",
    "- Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b038a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy\n",
    "CLSDS \n",
    "kf_dataset.csv SETPART >MATRIX DROP LOGITCOMP\n",
    "kf_dataset.csv SETPART >MATRIX TRAIN_TEST_SPLIT\n",
    "50 TRAIN_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8f696",
   "metadata": {},
   "source": [
    "Plot of training and validation loss\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy \n",
    "DUP PLOT_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy\n",
    "PLOT_ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82603d1b",
   "metadata": {},
   "source": [
    "K-fold cross validation\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb56fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy\n",
    "DROP SWAP DROP CROSSVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fb89f",
   "metadata": {},
   "source": [
    "ROC (Receiver Operator Characteristic) curve plot\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "It shows the diagnostic ability of binary classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cfpy\n",
    "CLSDS \n",
    "kf_dataset.csv SETPART >MATRIX TRAIN_TEST_SPLIT PLOTROC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d19fd7",
   "metadata": {},
   "source": [
    "Todo list/log application\n",
    "----------------------------------\n",
    "\n",
    "- GUI front-end is built in Lazarus.\n",
    "- It has two tabs, one for the list and the other for the log.\n",
    "- Dialog box is called as an executable.\n",
    "- The next cell executed has Creole Forth for Python code which uploads the saved text files to Dropbox.\n",
    "- The files in Dropbox can then be viewed from any device with access to Dropbox, such as an iPad or Android. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dropbox\n",
    "\n",
    "# ( -- ) Executes todo dialog box\n",
    "def doToDoDialog(gsp):\n",
    "    os.system('lazproj.exe')\n",
    "    return\n",
    "    \n",
    "cfb1.buildPrimitive(\"TODODLG\",doToDoDialog, \"doToDoDialog\", \"APPSPEC\", \"COMPINPF\",\"( -- ) Executes todo dialog box\")\n",
    "\n",
    "# ( access_token -- ) Uploads saved files to Dropbox\n",
    "def doDropBoxUploads(gsp):\n",
    "    returnVal = gsp.pop(gsp.DataStack)\n",
    "    access_token = gsp.Scratch\n",
    "    local_path1 = 'todo.txt'\n",
    "    dropbox_path1 = \"/todo.txt\"\n",
    "    local_path2 = 'dailylog.txt'\n",
    "    dropbox_path2 = \"/dailylog.txt\"\n",
    "    client = dropbox.Dropbox(access_token)\n",
    "    client.files_upload(open(local_path1, \"rb\").read(), dropbox_path1)\n",
    "    client.files_upload(open(local_path2, \"rb\").read(), dropbox_path2)\n",
    "    return 0\n",
    "\n",
    "cfb1.buildPrimitive(\"DB_UPLOADS\",doDropBoxUploads, \"doDropBoxUploads\", \"APPSPEC\", \"COMPINPF\",\n",
    "    \"( access_token -- ) Uploads saved files to Dropbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy TODODLG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15761502",
   "metadata": {},
   "source": [
    "To use the code below, you need a Dropbox account and to do the following steps: \n",
    "1. Go to the apps section at https://www.dropbox.com/developers/apps/ .\n",
    "2. Create a new app.\n",
    "3. Get the app key and app secret and put it in a safe place.\n",
    "4. Generate an access token. It will expire in a few hours without a refresh token. Creating a refesh token is outside\n",
    "   the scope of this demo. To use the code again if it expires, simply generate a new access token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12273da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.dropbox.com/developers/apps\n",
    "# If your access token doesn't work, just generate another one. \n",
    "access_token = 'sl.BcyjFoCbR9MpEFkthl68wGQHBhbNFhWpb5Lj-rCS6_cOl9bKw4B-m1huFXZORoK2ofQ7qJIKTzUNM0tvQC_1SpA9orrvv2n5brQTKW0bGFgl1egzfK1XPyXaye_9AItH2yxQx8zq'\n",
    "gsp.Scratch = access_token\n",
    "gsp.push(gsp.DataStack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cfpy DB_UPLOADS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8633107d",
   "metadata": {},
   "source": [
    "Summary\n",
    "-------------\n",
    "\n",
    "- Jupyter notebook is an effective IDE for interactive development.\n",
    "- A Forth written in Python can be adapted to use it without great effort. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85f5fa34",
   "metadata": {},
   "source": [
    "Questions/Comments?\n",
    "---------------------------------\n",
    "\n",
    "- Reach me at tiluser0@gmail.com\n",
    "- Code for demo is available on Github at https://github.com/tiluser/cfpy_jn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
